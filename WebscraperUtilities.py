import requests
import os
from bs4 import BeautifulSoup
import json

def getKeywords(keywordFile):
    keywordFile = os.getcwd() + "/keywords/" + keywordFile
    keywordList = []
    with open(keywordFile, 'r') as file:
        for line in file.readlines():
            keywordList.append(line.strip('\n'))
    return keywordList

#create request object to specified link then creates and returns
#a beautiful soup object from the websites content to parse through html
def getBeautifulSoupWebsiteSource(link):
    req = requests.get(link, allow_redirects=False)
    webpageContent = req.content
    return BeautifulSoup(webpageContent, "html.parser")

def writeJsonFile(toolFileName, pythonFileName, appList):
    #create json file and write contents of each app found to that file
    jsonFileName = 'cached/' + toolFileName.replace('.txt', '').replace(' ', '_') + '_' + pythonFileName.replace('.py', '') + ".json"
    with open(jsonFileName, 'w') as file:
        file.write("[\n")
        file.write(json.dumps(appList[0].__dict__))
        for i in range(1, len(appList)):
            file.write(",\n")
            file.write(json.dumps(appList[i].__dict__))
        file.write("\n]")